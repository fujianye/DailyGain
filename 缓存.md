缓存穿透
一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找（比如DB）。
一些恶意的请求会故意查询不存在的key,请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。
如何避免？
1：对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该key对应的数据insert了之后清理缓存。
2：对一定不存在的key进行过滤。可以把所有的可能存在的key放到一个大的Bitmap中，查询时通过该bitmap过滤。**例如bloomFilter,时间复杂度O(k)。**

缓存击穿？


缓存雪崩
当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，会给后端系统带来很大压力。导致系统崩溃。
如何避免？
1：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。**redis互斥锁setnx**
2：做二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期 **一级缓存 二级缓存**
3：不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。



缓存记录曝光和点击数量
日志记录曝光，日志统计（延时大）--> 缓存曝光数和点击，定时写到数据库（） --> 曝光和点击的去重 --> hyperloglog

秒杀系统实现（使用redis）
分3层：
1、CDN存储商品信息
2、redis读写分离（扩展只读节点的数量，提高读的并发能力）存储要秒杀的数量
3、库存在Redis中存储秒杀扣减的


**redis的watch机制** 
watch存储的数据结构（实际的数据结构不是这样的）：
watched_key:{key1:[client1,client2,client3,...],key2:[client5,client6,....],...}
client1:[key1,key2,...]
当被watch的key的值被修改时，同时也会update watched_key中对应key的client状态为“CLIENT_DIRTY_CAS”，
在事务提交时，检查client对应key被set(有可能set的值和之前一样)时，不执行事务。

redis事务回滚的实现方式？

redis lua脚本比事务的性能更高


司机每日流水收入明细
每日下班前并发量大，需要缓存

hash来分桶？





