一、前言
大数据应用一般会有采集、加工、存储、计算及可视化这几个环节。其中采集作为源头，在确保全面、准确、及时的前提下，最终加工出来的指标结果才是有价值的。而埋点作为一种重要的采集手段，可以将用户行为信息转化为数据资产，为产品分析、业务决策、广告推荐等提供可靠的流量数据支持。在业务需求少的情况下，可以运用一些简单的方法快速采集用户行为。但如果业务线、终端众多，数据需求多样，就需要设计好埋点模型和采集规范，工具化、平台化、流程化的管理来保证埋点的质量。

二、事件模型
首次需要思考的是，如何描述和记录用户的一次行为。这里我们使用的事件模型，即：

who 访客标识、设备指纹、登录 ID
when 事件发生时间、上报时间
where 设备环境、网络环境、业务环境等
what 事件标识、事件参数


我们设计了可以承载以上信息的日志模型，并保持必要的可扩展性，将数据映射到 schema 的各个字段中，一次行为便完整的记录下来。
三、采集方式
数据模型设计好后，接下来要考虑的是如何将客户端内的用户行为数据采集到服务端，这里主要依赖于客户端提供的监听能力。目前有赞支持两种采集方式：

3.1 无痕埋点（或全埋点）
利用浏览器或 APP 自带的监听方式，对用户的浏览页面、点击等行为进行收集，可以收集到的信息主要有：

页面的 url、APP 的包名等
点击元素的 xpath 路径、title 或约定的 dom 元素
无痕埋点的优势有：

前端接入成本低，不需要额外开发
用户动作收集完整，不会漏失
但同时也会存在以下问题：

有用、没用的数据都会收集
无法采集到特殊的行为动作、业务参数
采集到的信息需要进行二次标注，才可以被用户识别
当按钮的位置不固定、名称存在重复或页面重构时，无法做到准确的标识
无痕埋点在有赞一般用来做粗粒度的快速业务探索。


3.2 代码埋点
代码埋点是指依赖前端同学，自定义监听和收集处理。代码埋点的优势有：

事件标识明确
业务参数丰富
事件的触发方式可以灵活自定义
分析更方便、精确
随之而来的是以下问题：

前端代码的开发、管理成本
只能收集到事件上线之后的数据
在业务需求复杂，无痕埋点收集到的信息无法支持分析时，就需要进行代码埋点。

四、埋点 sdk
为简化前端同学的埋点开发工作，使其只需要关注于业务本身，并对埋点的一些约定进行必要的约束，有赞开发了多个端（js/ 小程序 /android/ios/java）的埋点 sdk。sdk 默认支持以下功能：

访客标识管理
会话管理
环境参数默认收集
参数的生命周期管理
默认事件的收集
跨端的 sdk 通信（如 app 嵌套 h5 页面）
内部业务的特殊处理逻辑
日志的格式化、合并、生命周期管理
日志的上报机制
前端同学通过 sdk 提供的接口进行开发，只需要关注：

SDK 的初始化配置
事件怎么标识
事件需要哪些参数
事件如何触发

五、日志中间层
数据收集上来后，原始日志还处于非常精简的状态，需要进一步加工成日志中间层，主要有以下几个环节：

批量上报的日志拆分
日志模型的格式化处理
信息的二次加工和维度扩展 如 IP、http_agent 的解析等
异常流量的清洗
会话信息的补充 如落地页、二跳页、停留时长的计算
按业务拆分日志流和日志表
实时流中间层是以 JSON 格式存储在 kafka 中，并且提供对应的 JavaBean 类，方便实时任务开发解析处理，并且也可以与 streamSql 相结合使用。

离线中间层是存储在同一个表中，字段与实时流格式保持一致，以日期和业务作为分区条件，并会自动创建所有业务的视图表，方便中间层的统一调整以及数仓的权限管理。

到这个阶段，有了通用的日志模型和 sdk，埋点工作可以标准化的开展起来。但随着承接的业务越来越多，更多的问题在等待着我们。

十、未来展望
目前埋点平台支撑了有赞微商城、零售、美业、精选、分销、有赞云、内部系统等十几条业务线，平均每月 20+ 新项目的项目，在支持已有流量需求的同时，我们也在思考如何进一步提升开发效率和发挥数据价值：

更加友好的平台引导，让不懂埋点的小白用户能快速上手
前端开发效率提升，sdk 与前端框架结合，可视化、配置化埋点
降低 sdk 上报的丢失率
全端的用户日志快捷查找，提升测试和排查问题效率
更智能的质量管理，快速定位和解决埋点问题
实时日志中间层与业务域的维度扩展
无痕埋点的页面自动归类标识
分析效率提升，与指标库打通，以及更易用的转化和归因模型来快速定位问题
支持算法 ABTest 实验分析
