分布式事务的实现方式有很多种，最具有代表性的是由Oracle Tuxedo系统提出的XA分布式事务协议。
XA协议包括两阶段提交（2PC）和三阶段提交（3PC）两种实现。2PC、3PC都是在跨库的DB层面。
1、2PC 是XA协议的一种。
第一阶段：请求/表决阶段。
就是在分布式事务的发起方在向分布式事务协调者（Coordinator）发送请求时，
Coordinator首先会分别向参与者（Partcipant）节点A、参与者（Partcipant）节点B分别发送事务预处理请求，称之为Prepare，有些资料也叫"Vote Request"。
第二阶段：提交/执行阶段（正常流程）
如果所有参与者节点都向协调者报告说“我这边可以处理”，那么此时协调者就会向所有参与者节点发送“全局提交确认通知（global_commit）”，
即你们都可以进行本地事务提交了，此时参与者节点就会各自进行本地的事务提交，并释放锁资源。最终将提交结果回复“ack”消息给Coordinator，
然后Coordinator就会向调用方返回分布式事务处理完成的结果。
第二阶段：提交/执行阶段（异常流程）
相反，在第二阶段除了所有的参与者节点都反馈“我这边可以处理了”的情况外，也会有节点反馈说“我这边不能处理”的情况发生，
此时参与者节点就会向协调者节点反馈“Vote_Abort”的消息。
此时分布式事务协调者节点就会向所有的参与者节点发起事务回滚的消息（“global_rollback”），
此时各个参与者节点就会在本地进行事务的回滚操作，回滚操作依照Undo Log来进行，释放锁资源。并且向协调者节点发送“ack”确认消息，
协调者节点就会向调用方返回分布式事务处理失败的结果。

XA-2PC提交协议中会遇到的一些问题：
1）性能问题。从流程上我们可以看得出，其最大缺点就在于它的执行过程中间，节点都处于阻塞状态。
各个操作数据库的节点此时都占用着数据库资源，只有当所有节点准备完毕，事务协调者才会通知进行全局提交，参与者进行本地事务提交后才会释放资源。
这样的过程会比较漫长，对性能影响比较大。
2）协调者单点故障问题。事务协调者是整个XA模型的核心，一旦事务协调者节点挂掉，会导致参与者收不到提交或回滚的通知，
从而导致参与者节点始终处于事务无法完成的中间状态。
3）丢失消息导致的数据不一致问题。在第二个阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，
另一部分事务参与者没收到提交消息，那么就会导致节点间数据的不一致问题。

2、3PC 也是XA协议的一种。
3PC在2PC提交的基础上增加了CanCommit阶段，并引入了超时机制。
CanCommit阶段的加入:多设置了一个缓冲阶段保证了在最后提交阶段之前各参与节点的状态是一致的.避免了一些2PC中第一阶段的不必要的数据库资源占用。
超时机制：一旦事务参与者迟迟没有收到协调者的Commit请求，就会在超时后自动进行本地commit，这样相对有效地解决了协调者单点故障的问题。

事实上XA也算分布式事务处理的规范了，但在为什么互联网中很少使用，究其原因我觉得有以下几个：
1）性能（阻塞性协议，增加响应时间、锁时间、死锁）；
2）数据库支持完善度（MySQL 5.7之前都有缺陷）；
3）协调者依赖独立的J2EE中间件（早期重量级Weblogic、Jboss、后期轻量级Atomikos、Narayana和Bitronix）；
4）运维复杂，DBA缺少这方面经验；
5）并不是所有资源都支持XA协议；
6）大厂懂所以不使用，小公司不懂所以不敢用。

3、TCC try-commit-cancel
2PC、3PC都是在跨库的DB层面，而TCC本质上就是一个应用层面的2PC，需要通过业务逻辑来实现。
TCC又称补偿事务。其核心思想是："针对每个操作都要注册一个与其对应的确认和补偿（撤销操作）"。
TCC的实现方式的优势在于，可以让应用自己定义数据库操作的粒度，使得降低锁冲突、提高吞吐量成为可能。
TCC需要通过业务逻辑实现3个关键点：1、每个分支（支付的内部渠道）都要实现try、confirm、cancel 3个接口；2、根据超时、系统故障等异常实现回滚逻辑；3、try、confirm、cancel 3个接口必须幂等。
TCC的commit-cancel阶段可以异步离线处理，可以不断重试。因为try阶段的结果就决定了commit一定可以执行成功或者一定失败，可以明确的执行commit或cancel.

4、MQ事务消息
对于常见的微服务系统，大部分接口调用是同步的，也就是一个服务直接调用另外一个服务的接口。
这个时候，用TCC分布式事务方案来保证各个接口的调用，要么一起成功，要么一起回滚，是比较合适的。
假如服务间的调用是异步的。也就是说，一个服务发送一个消息给消息中间件，比如RocketMQ、RabbitMQ、Kafka、ActiveMQ等等。
然后，另外一个服务从MQ消费到一条消息后进行处理。这就成了基于MQ的异步调用了。
那么针对这种基于MQ的异步调用，如何保证各个服务间的分布式事务呢？
也就是说，我希望的是基于MQ实现异步调用的多个服务的业务逻辑，要么一起成功，要么一起失败。
这个时候，就要用上可靠消息最终一致性方案，来实现分布式事务。

5、saga pattern


案例分析：
如订单系统与支付系统就会通过额外的业务逻辑设计来确保彼此之间的最终一致性，
如订单系统会通过订单的支付状态来保持与支付系统的数据一致，
而支付系统则会提供支付状态查询接口，或者实现最大可能的主动回调功能，来确保二者数据状态的最终一致。
此外可能还会通过日终的订单对账来发现不一致的数据，并进行数据校正。


小结：
2PC是数据库事务协议，缺点是：性能问题（长期占用数据库资源）、协调者单点、丢失消息会导致数据不一致。
3PC也是数据库事务协议，3PC相对于2PC的一个提高（相对缓解了2PC中的前两个问题），但是3PC依然没有完全解决数据不一致的问题。缺点是：性能问题（长期占用数据库资源）、协调者单点、丢失消息会导致数据不一致
TCC应用层面实现数据库操作，不占用数据库资源，提高吞吐量。缺点：对应用的侵入性非常强，业务逻辑的每个分支（支付的内部渠道）都需要实现try、confirm、cancel三个操作。此外，还需要按照网络状态、系统故障等不同的失败原因实现对应的回滚策略。为了满足一致性的要求，try confirm和cancel接口还必须实现幂等。
TCC的commit-cancel阶段可以异步离线处理，可以不断重试。

对比：
            2PC                                        3PC                              TCC
实现原理     DB协议                                     DB协议                            应用层面实现
性能        锁冲突、吞吐量低                          较少的锁冲突、较低吞吐量低              没有锁冲突、吞吐量高
单点        协调者单点，无法释放事务占用的数据库资源     协调者单点，超时机制可以自动提交事务        没有单点
一致性       各个参与者节点数据不一致                    各个参与者节点数据不一致               各个参与者节点数据可以达到较高一致   


分布式事务一直是业界难题，难在于CAP定理，在于分布式系统8大错误假设，在于FLP不可能原理，在于我们习惯于单机事务ACID做对比。
无论是数据库领域XA、Google percolator或Calvin模型，还是微服务下Saga、TCC、可靠消息等方案，都没有完美解决分布式事务问题，
它们不过是各自在性能、一致性、可用性等方面做取舍，寻求某些场景偏好下的权衡。

2PC、3PC参考：https://blog.csdn.net/bjweimengshu/article/details/86698036
事务消息参考：https://mp.weixin.qq.com/s?__biz=MzU3NDY4NzQwNQ==&mid=2247484388&idx=1&sn=fe37be7b3f06ca8519ff1f89e0ad006a&chksm=fd2fd226ca585b305db8323092d72d7b0f9480f1df7e8ab8223f285f80866b6fd047007827b2&scene=21#wechat_redirect
RocketMQ 参考：https://mp.weixin.qq.com/s?__biz=MzU3NDY4NzQwNQ==&mid=2247484461&idx=1&sn=72794d12ffe3c8ec3520fdba1c87c3b3&chksm=fd2fd5efca585cf955d240bbabd99b24262d255a3880454297f10a84e4c38445bc7b9d3ba339&scene=21#wechat_redirect
事务消息参考：http://silence.work/2018/08/22/RocketMQ-4-3%E4%BA%8B%E5%8A%A1%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%88%86%E6%9E%90/
参考：https://my.oschina.net/zhaoyi1/blog/3135469

